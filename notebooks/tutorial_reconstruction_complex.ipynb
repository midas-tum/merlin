{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example 04: Unrolled network on complex-valued data with complex-valued operations**\n",
    "We first define the data pipelines to feed the data into training, validation and test set. The MNIST database is used for showcasing. Since MNIST are real-valued images, a phase is simulated and added to the images to generate a complex-valued input. The fourier transformed image serves as k-space for data consistency. Single-MR-coil processing is performed. A retrospective undersampling according to a Parallel Imaging (PI) or Compressed Sensing (CS) like trajectory is simulated and applied to the data. The task of the network is to reconstruct the undersampled data with complex-valued operations.\n",
    "\n",
    "To enable GPU support in Google Colab, please go to `Edit -> Notebook settings` and select `GPU` as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect the available GPU hardware\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database pipeline\n",
    "Here starts the main part of the script. First define the data pipelines (in the form of generator functions) for training, validation and test set. Retrospective undersampling is performed inside the generator functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tutorial\n",
    "import merlintf\n",
    "\n",
    "# initialize some parameters\n",
    "accelerations = [2, 4]  # simulate retrospectively accelerations in the range of e.g. 2x to 4x\n",
    "accel_type = 'PI'  # simulated undersampling strategy: 'PI' = Parallel Imaging, 'CS' = Compressed Sensing\n",
    "center = 0.1  # percent of fully sampled central region along ky phase-encoding, e.g. 0.1 := floor(10% * 28) ky center lines = 2 ky center lines \n",
    "\n",
    "# Data Generators (Data pipeline) for complex-valued data with k-space\n",
    "# training set\n",
    "training_generator = tutorial.datasets.ComplexRawDataGeneratorMNIST(batch_size=32, \n",
    "                                    accelerations=accelerations,\n",
    "                                    accel_type=accel_type,\n",
    "                                    center=center, \n",
    "                                    shuffle=True,\n",
    "                                    mode='train')\n",
    "\n",
    "# validation set\n",
    "validation_generator = tutorial.datasets.ComplexRawDataGeneratorMNIST(batch_size=32, \n",
    "                                    accelerations=accelerations,\n",
    "                                    accel_type=accel_type,\n",
    "                                    center=center,\n",
    "                                    shuffle=False,\n",
    "                                    mode='val')\n",
    "\n",
    "# test set\n",
    "# ideally testing should be performed on prospectively accelerated acquisitions\n",
    "test_generator = tutorial.datasets.ComplexRawDataGeneratorMNIST(batch_size=1, \n",
    "                                    accelerations=accelerations,\n",
    "                                    accel_type=accel_type,\n",
    "                                    center=center,\n",
    "                                    shuffle=False,\n",
    "                                    mode='test')\n",
    "\n",
    "print('Training batches to process:', len(training_generator))\n",
    "print('Validation batches to process:', len(validation_generator))\n",
    "print('Test samples to process:', len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Define the CNN model as an unrolled network with intermittant data consistency blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-layer (residual) convolutional neural network (CNN) denoising regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define denoiser model\n",
    "class Denoiser(tf.keras.Model):\n",
    "    # initialize the required layers\n",
    "    def __init__(self, filters, kernel_size=(3,3), strides=(1,1), use_bias=True, activation=None, is_residual=False, name='denoiser'):\n",
    "        super().__init__(name=name)\n",
    "        self.is_residual = is_residual\n",
    "        self.conv_out1 = merlintf.keras.layers.ComplexConv2D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                strides=strides,\n",
    "                                padding='SAME',\n",
    "                                use_bias=use_bias,\n",
    "                                activation=activation)\n",
    "\n",
    "        self.conv_out2 = merlintf.keras.layers.ComplexConv2D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                strides=strides,\n",
    "                                padding='SAME',\n",
    "                                use_bias=use_bias,\n",
    "                                activation=activation)\n",
    "\n",
    "        self.conv_out3 = merlintf.keras.layers.ComplexConv2D(filters=1,\n",
    "                                kernel_size=kernel_size,\n",
    "                                strides=strides,\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=None)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv_out1(inputs)\n",
    "        x = self.conv_out2(x)\n",
    "        x = self.conv_out3(x)\n",
    "        if self.is_residual:\n",
    "            x = tf.keras.layers.Add()([inputs, x])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolled reconstruction network\n",
    "Combine denoising regularizer and data consistency blocks to an unrolled reconstruction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define unrolled reconstruction model\n",
    "class UnrolledNetwork(tf.keras.Model):\n",
    "    # initialize the required layers\n",
    "    def __init__(self, cascades, shared_params=True, is_residual=True, activation='ModReLU', name=None):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.T = 1 if shared_params else cascades  # shared denoiser network or (new) cascaded denoisers\n",
    "        self.T_end = cascades  # number of cascades\n",
    "\n",
    "        self.denoiser = [Denoiser(filters=8, is_residual=is_residual, activation=activation) for _ in range(self.T)]  # prepare denoising networks\n",
    "\n",
    "        A = merlintf.keras.layers.ForwardOp(center=True)\n",
    "        AH = merlintf.keras.layers.AdjointOp(center=True)\n",
    "\n",
    "        self.dc = [merlintf.keras.layers.DCGD(A, AH, weight_init=1.0, max_iter=10) for _ in range(self.T)]  # prepare data consistency blocks\n",
    "\n",
    "    # build the model in the forward path\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]                                       # undersampled image\n",
    "        for i in range(self.T_end):                         # unrolled network\n",
    "            ii = i % self.T\n",
    "            x = self.denoiser[ii](x)                    # denoising regularizer\n",
    "            x = self.dc[ii]([x,] + list(inputs[1:]))    # data consistency\n",
    "        return x\n",
    "    \n",
    "# instantiate a keras model as sub-class model\n",
    "# define network with model subclassing to control forward/backward path, training procedure, etc.\n",
    "model = UnrolledNetwork(cascades=5)\n",
    "# make one forward pass to initalize model\n",
    "inputs, _ = training_generator.__getitem__(0)\n",
    "output = model(inputs)\n",
    "\n",
    "# print model overview\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "Compile the model, assign an optimizer, loss function and validation metrics. Prepare some keras callbacks to monitor training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),      # used optimizer with chosen learning rate\n",
    "              loss='mse',                                                   # loss function \n",
    "              metrics=['mse', 'mae'])                                       # evaluation metrics (for training and validation set)\n",
    "\n",
    "# define callbacks to monitor model\n",
    "keras_callbacks = tutorial.get_callbacks(validation_generator, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "Start the Tensorboard [optional] to monitor training progress and display validation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Train the configured and compiled model. Monitor training progress with validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with training set and evaluate its performance with the validation set\n",
    "model.fit(training_generator,                       # training set\n",
    "          validation_data=validation_generator,     # validation set\n",
    "          epochs=3,                                 # number of epochs to train the model\n",
    "          callbacks=keras_callbacks)                # callbacks to monitor or control training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Test the trained model to predict a denoised output and to display performance (metrics) on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate trained model\n",
    "loss_metric_test = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with trained model\n",
    "inputs, outputs = test_generator.__getitem__(0)\n",
    "predicted_output = model.predict(inputs)\n",
    "\n",
    "# display the predicted output\n",
    "import matplotlib.pyplot as plt\n",
    "icase = 0  # display the first example\n",
    "plt.figure()\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(np.squeeze(np.abs(inputs[0][icase,])), cmap='gray')\n",
    "plt.title('Magnitude - Noisy')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(np.squeeze(np.abs(predicted_output[icase,])), cmap='gray')\n",
    "plt.title('Magnitude - Recon')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(np.squeeze(np.abs(outputs[icase,])), cmap='gray')\n",
    "plt.title('Magnitude - Target')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(np.squeeze(np.angle(inputs[0][icase,])), vmin=-np.pi, vmax=np.pi)\n",
    "plt.title('Phase - Noisy')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(np.squeeze(np.angle(predicted_output[icase,])), vmin=-np.pi, vmax=np.pi)\n",
    "plt.title('Phase - Recon')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(np.squeeze(np.angle(outputs[icase,])), vmin=-np.pi, vmax=np.pi)\n",
    "plt.title('Phase - Target')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26c4402bb8476a31d8c429f22841c868a499a7e31d9c723639b1a5309d819501"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('optox_midas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
