{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UvPOKBO55l4e"
      },
      "source": [
        "# **Example 02: Denoising on complex-valued data with real-valued operations**\n",
        "We first define the data pipelines to feed the data into training, validation and test set. The MNIST database is used for showcasing. Since MNIST are real-valued images, a phase is simulated and added to the images to generate a complex-valued input. A white Gaussian noise is simulated retrospectively and added to the data. The task of the network is to denoise the images with real-valued operations, i.e. complex data is stored in channel dimension as 2 real-valued tensors. You can compare the different processing to the pure real-valued case (Example 01) and to handling the complex-valued data with complex-valued operations (Example 02).\n",
        "\n",
        "To enable GPU support in Google Colab, please go to `Edit -> Notebook settings` and select `GPU` as hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EIp-PHi5l4h"
      },
      "outputs": [],
      "source": [
        "# inspect the available GPU hardware\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QJcsMKoR5l4m"
      },
      "source": [
        "## Database pipeline\n",
        "Here starts the main part of the script. First define the data pipelines (in the form of generator functions) for training, validation and test set. Retrospective noise simulation is performed inside the generator functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmbp-5VU5l4o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import merlintf\n",
        "import tutorial\n",
        "\n",
        "# initialize some parameters\n",
        "noise_level = 0.5  # simulated additive white Gaussian noise level\n",
        "\n",
        "# Data Generators (Data pipeline) for complex-valued data\n",
        "# training set\n",
        "training_generator = tutorial.datasets.ComplexDataGeneratorMNIST(batch_size=32, \n",
        "                                    noise_level=noise_level,\n",
        "                                    shuffle=True,\n",
        "                                    mode='train')\n",
        "\n",
        "# validation set\n",
        "validation_generator = tutorial.datasets.ComplexDataGeneratorMNIST(batch_size=32, \n",
        "                                    noise_level=noise_level,\n",
        "                                    shuffle=False,\n",
        "                                    mode='val')\n",
        "\n",
        "# test set\n",
        "# ideally testing should be performed on real noisy cases and not simulated ones\n",
        "test_generator = tutorial.datasets.ComplexDataGeneratorMNIST(batch_size=1,   \n",
        "                                    shuffle=False,\n",
        "                                    mode='test')\n",
        "\n",
        "print('Training batches to process:', len(training_generator))\n",
        "print('Validation batches to process:', len(validation_generator))\n",
        "print('Test samples to process:', len(test_generator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nPj6Z2kQ5l4r"
      },
      "source": [
        "## Model\n",
        "Define the CNN model with its corresponding inputs and outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "q3yuIDDA5l4s"
      },
      "source": [
        "### 3-layer convolutional neural network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJetEPYP5l4t"
      },
      "outputs": [],
      "source": [
        "# Generate Model\n",
        "# Let's start with a 3-layer CNN\n",
        "input = tf.keras.Input(shape=(28, 28, 1), dtype='complex64')  # define input layer and its shape, complex-valued tensors\n",
        "activation = 'relu'  # select activation function: real-valued ReLU\n",
        "# conversion layer from complex-valued to 2-channel real-valued \n",
        "input_2chreal = merlintf.complex2real(input)  \n",
        "# Alternatively, you could directly define a 2-channel real-valued input and feed the real/magnitude and imaginary/phase data from the database pipeline into the respective channels \n",
        "# input_2chreal = tf.keras.Input(shape=(28, 28, 2), dtype='float32')  # requires adaption in database pipeline\n",
        "\n",
        "# convolutional layer 1: Real-valued convolution\n",
        "conv_out1 = tf.keras.layers.Conv2D(filters=4,                           # output channels, N_fout\n",
        "                                kernel_size=(3,3),                      # kernel size along x and y\n",
        "                                strides=(1,1),                          # stride performed along x and y\n",
        "                                padding='SAME',                         # padding of input to adjust output size\n",
        "                                use_bias=True,                          # learn bias values for conv layer\n",
        "                                activation=activation)(input_2chreal)   # apply activation function after conv operation\n",
        "# convolutional layer 2: Real-valued convolution\n",
        "conv_out2 = tf.keras.layers.Conv2D(filters=4,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out1)\n",
        "# convolutional layer 3: Real-valued convolution\n",
        "output_2chreal = tf.keras.layers.Conv2D(filters=2,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out2)\n",
        "# conversion layer from 2-channel real-valued to complex-valued \n",
        "output = merlintf.real2complex(output_2chreal)\n",
        "\n",
        "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
        "model = tf.keras.Model(input, output, name='3layerCNN2ch')\n",
        "\n",
        "# print model overview\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LHjce5tx5l4x"
      },
      "source": [
        "### 3-layer residual convolutional neural network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlBVN-KF5l4y"
      },
      "outputs": [],
      "source": [
        "# Generate Model\n",
        "# Let's start with a residual 3-layer CNN\n",
        "input = tf.keras.Input(shape=(28, 28, 1), dtype='complex64')  # define input layer and its shape, complex-valued tensors\n",
        "activation = 'relu'  # select activation function: real-valued ReLU\n",
        "# conversion layer from complex-valued to 2-channel real-valued \n",
        "input_2chreal = merlintf.complex2real(input)\n",
        "# Alternatively, you could directly define a 2-channel real-valued input and feed the real/magnitude and imaginary/phase data from the database pipeline into the respective channels \n",
        "# input_2chreal = tf.keras.Input(shape=(28, 28, 2), dtype='float32')  # requires adaption in database pipeline\n",
        "\n",
        "# convolutional layer 1: Real-valued convolution\n",
        "conv_out1 = tf.keras.layers.Conv2D(filters=4,                           # output channels, N_fout\n",
        "                                kernel_size=(3,3),                      # kernel size along x and y\n",
        "                                strides=(1,1),                          # stride performed along x and y\n",
        "                                padding='SAME',                         # padding of input to adjust output size\n",
        "                                use_bias=True,                          # learn bias values for conv layer\n",
        "                                activation=activation)(input_2chreal)   # apply activation function after conv operation\n",
        "# convolutional layer 2: Real-valued convolution\n",
        "conv_out2 = tf.keras.layers.Conv2D(filters=4,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out1)\n",
        "# convolutional layer 3: Real-valued convolution\n",
        "residual  = tf.keras.layers.Conv2D(filters=2,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out2)\n",
        "# residual connection\n",
        "output_2chreal = tf.keras.layers.Add()([input_2chreal, residual])\n",
        "\n",
        "# conversion layer from 2-channel real-valued to complex-valued \n",
        "output = merlintf.real2complex(output_2chreal)\n",
        "\n",
        "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
        "model = tf.keras.Model(input, output, name='Residual3layerCNN2ch')\n",
        "\n",
        "# print model overview\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LYE9sE7D5l41"
      },
      "source": [
        "### Build model\n",
        "Compile the model, assign an optimizer, loss function and validation metrics. Prepare some keras callbacks to monitor training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXNK9vnT5l42"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),      # used optimizer with chosen learning rate\n",
        "              loss='mse',                                                   # loss function \n",
        "              metrics=['mse', 'mae'])                                       # evaluation metrics (for training and validation set)\n",
        "\n",
        "# define callbacks to monitor model\n",
        "keras_callbacks = tutorial.get_callbacks(validation_generator, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ssxFfSC15l43"
      },
      "source": [
        "## Tensorboard\n",
        "Start the Tensorboard [optional] to monitor training progress and display validation outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZT1YPR55l44"
      },
      "outputs": [],
      "source": [
        "# start Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ZnWQfejD5l45"
      },
      "source": [
        "## Training\n",
        "Train the configured and compiled model. Monitor training progress with validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1idUkP_d5l46"
      },
      "outputs": [],
      "source": [
        "# train model with training set and evaluate its performance with the validation set\n",
        "model.fit(training_generator,                       # training set\n",
        "          validation_data=validation_generator,     # validation set\n",
        "          epochs=3,                                 # number of epochs to train the model\n",
        "          callbacks=keras_callbacks)                # callbacks to monitor or control training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7fOwa0Jt5l47"
      },
      "source": [
        "## Testing\n",
        "Test the trained model to predict a denoised output and to display performance (metrics) on test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2n8wnZU5l47"
      },
      "outputs": [],
      "source": [
        "# predict with trained model\n",
        "predicted_output = model.predict(test_generator)\n",
        "\n",
        "# evaluate trained model\n",
        "loss_metric_test = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display the predicted output\n",
        "import matplotlib.pyplot as plt\n",
        "icase = 0  # display the first example\n",
        "plt.figure()\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(np.squeeze(np.abs(predicted_output[icase,])), cmap='gray')\n",
        "plt.title('Magnitude')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(np.squeeze(np.angle(predicted_output[icase,])))\n",
        "plt.title('Phase')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tutorial_denoising_2chreal.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "26c4402bb8476a31d8c429f22841c868a499a7e31d9c723639b1a5309d819501"
    },
    "kernelspec": {
      "display_name": "Python 3.6.11 64-bit ('optox_midas': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
