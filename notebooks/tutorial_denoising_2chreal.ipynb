{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UvPOKBO55l4e"
      },
      "source": [
        "# **Example 02: Denoising on complex-valued data with real-valued operations**\n",
        "We first define the data pipelines to feed the data into training, validation and test set. The MNIST database is used for showcasing. Since MNIST are real-valued images, a phase is simulated and added to the images to generate a complex-valued input. A white Gaussian noise is simulated retrospectively and added to the data. The task of the network is to denoise the images with real-valued operations, i.e. complex data is stored in channel dimension as 2 real-valued tensors. You can compare the different processing to the pure real-valued case (Example 01) and to handling the complex-valued data with complex-valued operations (Example 02).\n",
        "\n",
        "To enable GPU support in Google Colab, please go to `Edit -> Notebook settings` and select `GPU` as hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EIp-PHi5l4h"
      },
      "outputs": [],
      "source": [
        "# inspect the available GPU hardware\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QJcsMKoR5l4m"
      },
      "source": [
        "## Database pipeline\n",
        "Here starts the main part of the script. First define the data pipelines (in the form of generator functions) for training, validation and test set. Retrospective noise simulation is performed inside the generator functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zmbp-5VU5l4o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training batches to process: 1500\n",
            "Validation batches to process: 375\n",
            "Test samples to process: 10000\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import merlintf\n",
        "import tutorial\n",
        "\n",
        "# initialize some parameters\n",
        "noise_level = 0.5  # simulated additive white Gaussian noise level\n",
        "\n",
        "# Data Generators (Data pipeline) for complex-valued data\n",
        "# training set\n",
        "training_generator = tutorial.datasets.ComplexDataGeneratorMNIST(batch_size=32, \n",
        "                                    noise_level=noise_level,\n",
        "                                    shuffle=True,\n",
        "                                    mode='train')\n",
        "\n",
        "# validation set\n",
        "validation_generator = tutorial.datasets.ComplexDataGeneratorMNIST(batch_size=32, \n",
        "                                    noise_level=noise_level,\n",
        "                                    shuffle=False,\n",
        "                                    mode='val')\n",
        "\n",
        "# test set\n",
        "# ideally testing should be performed on real noisy cases and not simulated ones\n",
        "test_generator = tutorial.datasets.ComplexDataGeneratorMNIST(batch_size=1,   \n",
        "                                    shuffle=False,\n",
        "                                    mode='test')\n",
        "\n",
        "print('Training batches to process:', len(training_generator))\n",
        "print('Validation batches to process:', len(validation_generator))\n",
        "print('Test samples to process:', len(test_generator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nPj6Z2kQ5l4r"
      },
      "source": [
        "## Model\n",
        "Define the CNN model with its corresponding inputs and outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "q3yuIDDA5l4s"
      },
      "source": [
        "### 3-layer convolutional neural network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fJetEPYP5l4t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"3layerCNN2ch\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.real (TFOpLambda)       (None, 28, 28, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.imag (TFOpLambda)       (None, 28, 28, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, 28, 28, 2)    0           tf.math.real[0][0]               \n",
            "                                                                 tf.math.imag[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 8)    152         tf.concat[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 8)    584         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 2)    146         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.split (TFOpLambda)           [(None, 28, 28, 1),  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.dtypes.complex (TFOpLambda)  (None, 28, 28, 1)    0           tf.split[0][0]                   \n",
            "                                                                 tf.split[0][1]                   \n",
            "==================================================================================================\n",
            "Total params: 882\n",
            "Trainable params: 882\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Generate Model\n",
        "# Let's start with a 3-layer CNN\n",
        "input = tf.keras.Input(shape=(28, 28, 1), dtype='complex64')  # define input layer and its shape, complex-valued tensors\n",
        "activation = 'relu'  # select activation function: real-valued ReLU\n",
        "# conversion layer from complex-valued to 2-channel real-valued \n",
        "input_2chreal = merlintf.complex2real(input)  \n",
        "# Alternatively, you could directly define a 2-channel real-valued input and feed the real/magnitude and imaginary/phase data from the database pipeline into the respective channels \n",
        "# input_2chreal = tf.keras.Input(shape=(28, 28, 2), dtype='float32')  # requires adaption in database pipeline\n",
        "\n",
        "# convolutional layer 1: Real-valued convolution\n",
        "conv_out1 = tf.keras.layers.Conv2D(filters=8,                           # output channels, N_fout\n",
        "                                kernel_size=(3,3),                      # kernel size along x and y\n",
        "                                strides=(1,1),                          # stride performed along x and y\n",
        "                                padding='SAME',                         # padding of input to adjust output size\n",
        "                                use_bias=True,                          # learn bias values for conv layer\n",
        "                                activation=activation)(input_2chreal)   # apply activation function after conv operation\n",
        "# convolutional layer 2: Real-valued convolution\n",
        "conv_out2 = tf.keras.layers.Conv2D(filters=8,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out1)\n",
        "# convolutional layer 3: Real-valued convolution\n",
        "output_2chreal = tf.keras.layers.Conv2D(filters=2,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out2)\n",
        "# conversion layer from 2-channel real-valued to complex-valued \n",
        "output = merlintf.real2complex(output_2chreal)\n",
        "\n",
        "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
        "model = tf.keras.Model(input, output, name='3layerCNN2ch')\n",
        "\n",
        "# print model overview\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LHjce5tx5l4x"
      },
      "source": [
        "### 3-layer residual convolutional neural network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mlBVN-KF5l4y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Residual3layerCNN2ch\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.real_1 (TFOpLambda)     (None, 28, 28, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.imag_1 (TFOpLambda)     (None, 28, 28, 1)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_1 (TFOpLambda)        (None, 28, 28, 2)    0           tf.math.real_1[0][0]             \n",
            "                                                                 tf.math.imag_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 8)    152         tf.concat_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 8)    584         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 2)    146         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 28, 28, 2)    0           tf.concat_1[0][0]                \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.split_1 (TFOpLambda)         [(None, 28, 28, 1),  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "tf.dtypes.complex_1 (TFOpLambda (None, 28, 28, 1)    0           tf.split_1[0][0]                 \n",
            "                                                                 tf.split_1[0][1]                 \n",
            "==================================================================================================\n",
            "Total params: 882\n",
            "Trainable params: 882\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Generate Model\n",
        "# Let's start with a residual 3-layer CNN\n",
        "input = tf.keras.Input(shape=(28, 28, 1), dtype='complex64')  # define input layer and its shape, complex-valued tensors\n",
        "activation = 'relu'  # select activation function: real-valued ReLU\n",
        "# conversion layer from complex-valued to 2-channel real-valued \n",
        "input_2chreal = merlintf.complex2real(input)\n",
        "# Alternatively, you could directly define a 2-channel real-valued input and feed the real/magnitude and imaginary/phase data from the database pipeline into the respective channels \n",
        "# input_2chreal = tf.keras.Input(shape=(28, 28, 2), dtype='float32')  # requires adaption in database pipeline\n",
        "\n",
        "# convolutional layer 1: Real-valued convolution\n",
        "conv_out1 = tf.keras.layers.Conv2D(filters=8,                           # output channels, N_fout\n",
        "                                kernel_size=(3,3),                      # kernel size along x and y\n",
        "                                strides=(1,1),                          # stride performed along x and y\n",
        "                                padding='SAME',                         # padding of input to adjust output size\n",
        "                                use_bias=True,                          # learn bias values for conv layer\n",
        "                                activation=activation)(input_2chreal)   # apply activation function after conv operation\n",
        "# convolutional layer 2: Real-valued convolution\n",
        "conv_out2 = tf.keras.layers.Conv2D(filters=8,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out1)\n",
        "# convolutional layer 3: Real-valued convolution\n",
        "residual  = tf.keras.layers.Conv2D(filters=2,\n",
        "                                kernel_size=(3,3),\n",
        "                                strides=(1,1),\n",
        "                                padding='SAME',\n",
        "                                use_bias=True,\n",
        "                                activation=activation)(conv_out2)\n",
        "# residual connection\n",
        "output_2chreal = tf.keras.layers.Add()([input_2chreal, residual])\n",
        "\n",
        "# conversion layer from 2-channel real-valued to complex-valued \n",
        "output = merlintf.real2complex(output_2chreal)\n",
        "\n",
        "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
        "model = tf.keras.Model(input, output, name='Residual3layerCNN2ch')\n",
        "\n",
        "# print model overview\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LYE9sE7D5l41"
      },
      "source": [
        "### Build model\n",
        "Compile the model, assign an optimizer, loss function and validation metrics. Prepare some keras callbacks to monitor training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EXNK9vnT5l42"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),      # used optimizer with chosen learning rate\n",
        "              loss='mse',                                                   # loss function \n",
        "              metrics=['mse', 'mae'])                                       # evaluation metrics (for training and validation set)\n",
        "\n",
        "# define callbacks to monitor model\n",
        "keras_callbacks = tutorial.get_callbacks(validation_generator, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ssxFfSC15l43"
      },
      "source": [
        "## Tensorboard\n",
        "Start the Tensorboard [optional] to monitor training progress and display validation outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZT1YPR55l44"
      },
      "outputs": [],
      "source": [
        "# start Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ZnWQfejD5l45"
      },
      "source": [
        "## Training\n",
        "Train the configured and compiled model. Monitor training progress with validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1idUkP_d5l46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1500/1500 [==============================] - 8s 4ms/step - loss: 0.0855 - mse: 0.0443 - mae: 0.1531 - val_loss: 0.0676 - val_mse: 0.0338 - val_mae: 0.1175\n",
            "Epoch 2/3\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0674 - mse: 0.0337 - mae: 0.1167 - val_loss: 0.0672 - val_mse: 0.0335 - val_mae: 0.1153\n",
            "Epoch 3/3\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0672 - mse: 0.0335 - mae: 0.1152 - val_loss: 0.0670 - val_mse: 0.0334 - val_mae: 0.1144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f54801035c0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train model with training set and evaluate its performance with the validation set\n",
        "model.fit(training_generator,                       # training set\n",
        "          validation_data=validation_generator,     # validation set\n",
        "          epochs=3,                                 # number of epochs to train the model\n",
        "          callbacks=keras_callbacks)                # callbacks to monitor or control training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7fOwa0Jt5l47"
      },
      "source": [
        "## Testing\n",
        "Test the trained model to predict a denoised output and to display performance (metrics) on test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k2n8wnZU5l47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0036 - mse: 0.0018 - mae: 0.0286\n"
          ]
        }
      ],
      "source": [
        "# evaluate trained model\n",
        "loss_metric_test = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# predict with trained model\n",
        "inputs, outputs = test_generator.__getitem__(0)\n",
        "predicted_output = model.predict(inputs)\n",
        "\n",
        "# display the predicted output\n",
        "import matplotlib.pyplot as plt\n",
        "icase = 0  # display the first example\n",
        "plt.figure()\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(np.squeeze(np.abs(inputs[icase,])), cmap='gray')\n",
        "plt.title('Magnitude - Noisy')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,3,2)\n",
        "plt.imshow(np.squeeze(np.abs(predicted_output[icase,])), cmap='gray')\n",
        "plt.title('Magnitude - Recon')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,3,3)\n",
        "plt.imshow(np.squeeze(np.abs(outputs[icase,])), cmap='gray')\n",
        "plt.title('Magnitude - Target')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,3,4)\n",
        "plt.imshow(np.squeeze(np.angle(inputs[icase,])), vmin=-np.pi, vmax=np.pi)\n",
        "plt.title('Phase - Noisy')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,3,5)\n",
        "plt.imshow(np.squeeze(np.angle(predicted_output[icase,])), vmin=-np.pi, vmax=np.pi)\n",
        "plt.title('Phase - Recon')\n",
        "plt.axis('off')\n",
        "plt.subplot(2,3,6)\n",
        "plt.imshow(np.squeeze(np.angle(outputs[icase,])), vmin=-np.pi, vmax=np.pi)\n",
        "plt.title('Phase - Target')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tutorial_denoising_2chreal.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "26c4402bb8476a31d8c429f22841c868a499a7e31d9c723639b1a5309d819501"
    },
    "kernelspec": {
      "display_name": "Python 3.6.11 64-bit ('optox_midas': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
