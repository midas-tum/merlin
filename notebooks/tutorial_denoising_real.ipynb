{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHO2vsevaypz"
   },
   "source": [
    "# **Example 01: Denoising on real-valued data**\n",
    "We first define the data pipelines to feed the data into training, validation and test set. The MNIST database is used for showcasing. A white Gaussian noise is simulated retrospectively and added to the data. The task of the network is to denoise the images with real-valued operations.\n",
    "\n",
    "To enable GPU support in Google Colab, please go to `Edit -> Notebook settings` and select `GPU` as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiHgfpoyawEo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect the available GPU hardware\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywBf1W9FhscY"
   },
   "source": [
    "## Database pipeline\n",
    "Here starts the main part of the script. First define the data pipelines (in the form of generator functions) for training, validation and test set. Retrospective noise simulation is performed inside the generator functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuRmjhAjawE5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import tutorial\n",
    "import merlintf\n",
    "\n",
    "# initialize some parameters\n",
    "noise_level = 0.5  # simulated additive white Gaussian noise level\n",
    "\n",
    "# Data Generators (Data pipeline) for real-valued data\n",
    "# training set\n",
    "training_generator = tutorial.datasets.DataGeneratorMNIST(batch_size=32, \n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=True,\n",
    "                                    mode='train')\n",
    "\n",
    "# validation set\n",
    "validation_generator = tutorial.datasets.DataGeneratorMNIST(batch_size=32, \n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=False,\n",
    "                                    mode='val')\n",
    "\n",
    "# test set\n",
    "# ideally testing should be performed on real noisy cases and not simulated ones\n",
    "test_generator = tutorial.datasets.DataGeneratorMNIST(batch_size=1,\n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=False,\n",
    "                                    mode='test')\n",
    "\n",
    "print('Training batches to process:', len(training_generator))\n",
    "print('Validation batches to process:', len(validation_generator))\n",
    "print('Test samples to process:', len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ofBpMc_iXbQ"
   },
   "source": [
    "## Model\n",
    "Define the CNN model with its corresponding inputs and outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vHuf103C72N"
   },
   "source": [
    "### 3-layer convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lj5ww7q2awE_"
   },
   "outputs": [],
   "source": [
    "# Generate Model\n",
    "# Let's start with a 3-layer CNN\n",
    "input = tf.keras.Input(shape=(28, 28, 1),)  # define input layer and its shape\n",
    "activation = 'relu'  # select activation function: real-valued ReLU\n",
    "# convolutional layer 1: Real-valued convolution\n",
    "conv_out1 = tf.keras.layers.Conv2D(filters=4,                   # output channels, N_fout\n",
    "                                kernel_size=(3,3),              # kernel size along x and y\n",
    "                                strides=(1,1),                  # stride performed along x and y\n",
    "                                padding='SAME',                 # padding of input to adjust output size\n",
    "                                use_bias=True,                  # learn bias values for conv layer\n",
    "                                activation=activation)(input)   # apply activation function after conv operation\n",
    "# convolutional layer 2: Real-valued convolution\n",
    "conv_out2 = tf.keras.layers.Conv2D(filters=4,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out1)\n",
    "# convolutional layer 3: Real-valued convolution\n",
    "output    = tf.keras.layers.Conv2D(filters=1,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out2)\n",
    "\n",
    "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
    "model = tf.keras.Model(input, output, name='3layerCNN')\n",
    "\n",
    "# print model overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwyIPXXVi4mH"
   },
   "source": [
    "### 3-layer residual convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gy8yDBVFawFE"
   },
   "outputs": [],
   "source": [
    "# Generate Model\n",
    "# Let's start with a residual 3-layer CNN\n",
    "input = tf.keras.Input(shape=(28, 28, 1),)  # define input layer and its shape\n",
    "activation = 'relu'  # select activation function\n",
    "# convolutional layer 1\n",
    "conv_out1 = tf.keras.layers.Conv2D(filters=4,                   # output channels, N_fout\n",
    "                                kernel_size=(3,3),              # kernel size along x and y\n",
    "                                strides=(1,1),                  # stride performed along x and y\n",
    "                                padding='SAME',                 # padding of input to adjust output size\n",
    "                                use_bias=True,                  # learn bias values for conv layer\n",
    "                                activation=activation)(input)   # apply activation function after conv operation\n",
    "# convolutional layer 2\n",
    "conv_out2 = tf.keras.layers.Conv2D(filters=4,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out1)\n",
    "# convolutional layer 3\n",
    "residual    = tf.keras.layers.Conv2D(filters=1,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out2)\n",
    "# residual connection\n",
    "output = tf.keras.layers.Add()([input, residual])\n",
    "\n",
    "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
    "model = tf.keras.Model(input, output, name='Residual3layerCNN')\n",
    "\n",
    "# print model overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLtH7LN3jBaw"
   },
   "source": [
    "### Build model\n",
    "Compile the model, assign an optimizer, loss function and validation metrics. Prepare some keras callbacks to monitor training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO-aSnHDawFJ"
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),      # used optimizer with chosen learning rate\n",
    "              loss='mse',                                                   # loss function \n",
    "              metrics=['mse', 'mae'])                                       # evaluation metrics (for training and validation set)\n",
    "\n",
    "# define callbacks to monitor model\n",
    "keras_callbacks = tutorial.get_callbacks(validation_generator, model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBZObgNmBrzu"
   },
   "source": [
    "## Tensorboard\n",
    "Start the Tensorboard [optional] to monitor training progress and display validation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRkAJB8nawFQ"
   },
   "outputs": [],
   "source": [
    "# start Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jskfeAhyB3KN"
   },
   "source": [
    "## Training\n",
    "Train the configured and compiled model. Monitor training progress with validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBCEzPcQawFT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train model with training set and evaluate its performance with the validation set\n",
    "model.fit(training_generator,                     # training set\n",
    "          validation_data=validation_generator,   # validation set\n",
    "          epochs=3,                               # number of epochs to train the model\n",
    "          callbacks=keras_callbacks)              # callbacks to monitor or control training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qlWxTOzCApS"
   },
   "source": [
    "## Testing\n",
    "Test the trained model to predict a denoised output and to display performance (metrics) on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPWDzA18awFZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# predict with trained model\n",
    "predicted_output = model.predict(test_generator)\n",
    "\n",
    "# evaluate trained model\n",
    "loss_metric_test = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the predicted output\n",
    "import matplotlib.pyplot as plt\n",
    "icase = 0  # display the first example\n",
    "plt.imshow(np.squeeze(predicted_output[icase,]), cmap=plt.gray())\n",
    "plt.title('Result')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tutorial_denoising_real.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "26c4402bb8476a31d8c429f22841c868a499a7e31d9c723639b1a5309d819501"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('optox_midas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
