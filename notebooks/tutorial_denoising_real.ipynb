{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHO2vsevaypz"
   },
   "source": [
    "# **Example 01: Denoising on real-valued data**\n",
    "We first define the data pipelines to feed the data into training, validation and test set. The MNIST database is used for showcasing. A white Gaussian noise is simulated retrospectively and added to the data. The task of the network is to denoise the images with real-valued operations.\n",
    "\n",
    "To enable GPU support in Google Colab, please go to `Edit -> Notebook settings` and select `GPU` as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiHgfpoyawEo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect the available GPU hardware\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywBf1W9FhscY"
   },
   "source": [
    "## Database pipeline\n",
    "Here starts the main part of the script. First define the data pipelines (in the form of generator functions) for training, validation and test set. Retrospective noise simulation is performed inside the generator functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XuRmjhAjawE5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches to process: 1500\n",
      "Validation batches to process: 375\n",
      "Test samples to process: 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tutorial\n",
    "\n",
    "# initialize some parameters\n",
    "noise_level = 0.5  # simulated additive white Gaussian noise level\n",
    "\n",
    "# Data Generators (Data pipeline) for real-valued data\n",
    "# training set\n",
    "training_generator = tutorial.datasets.DataGeneratorMNIST(batch_size=32, \n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=True,\n",
    "                                    mode='train')\n",
    "\n",
    "# validation set\n",
    "validation_generator = tutorial.datasets.DataGeneratorMNIST(batch_size=32, \n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=False,\n",
    "                                    mode='val')\n",
    "\n",
    "# test set\n",
    "# ideally testing should be performed on real noisy cases and not simulated ones\n",
    "test_generator = tutorial.datasets.DataGeneratorMNIST(batch_size=1,\n",
    "                                    noise_level=noise_level,\n",
    "                                    shuffle=False,\n",
    "                                    mode='test')\n",
    "\n",
    "print('Training batches to process:', len(training_generator))\n",
    "print('Validation batches to process:', len(validation_generator))\n",
    "print('Test samples to process:', len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ofBpMc_iXbQ"
   },
   "source": [
    "## Model\n",
    "Define the CNN model with its corresponding inputs and outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vHuf103C72N"
   },
   "source": [
    "### 3-layer convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lj5ww7q2awE_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3layerCNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 1)         73        \n",
      "=================================================================\n",
      "Total params: 737\n",
      "Trainable params: 737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generate Model\n",
    "# Let's start with a 3-layer CNN\n",
    "input = tf.keras.Input(shape=(28, 28, 1),)  # define input layer and its shape\n",
    "activation = 'relu'  # select activation function: real-valued ReLU\n",
    "# convolutional layer 1: Real-valued convolution\n",
    "conv_out1 = tf.keras.layers.Conv2D(filters=8,                   # output channels, N_fout\n",
    "                                kernel_size=(3,3),              # kernel size along x and y\n",
    "                                strides=(1,1),                  # stride performed along x and y\n",
    "                                padding='SAME',                 # padding of input to adjust output size\n",
    "                                use_bias=True,                  # learn bias values for conv layer\n",
    "                                activation=activation)(input)   # apply activation function after conv operation\n",
    "# convolutional layer 2: Real-valued convolution\n",
    "conv_out2 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out1)\n",
    "# convolutional layer 3: Real-valued convolution\n",
    "output    = tf.keras.layers.Conv2D(filters=1,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out2)\n",
    "\n",
    "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
    "model = tf.keras.Model(input, output, name='3layerCNN')\n",
    "\n",
    "# print model overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwyIPXXVi4mH"
   },
   "source": [
    "### 3-layer residual convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gy8yDBVFawFE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Residual3layerCNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 8)    80          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 8)    584         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 1)    73          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 28, 28, 1)    0           input_2[0][0]                    \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 737\n",
      "Trainable params: 737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generate Model\n",
    "# Let's start with a residual 3-layer CNN\n",
    "input = tf.keras.Input(shape=(28, 28, 1),)  # define input layer and its shape\n",
    "activation = 'relu'  # select activation function\n",
    "# convolutional layer 1\n",
    "conv_out1 = tf.keras.layers.Conv2D(filters=8,                   # output channels, N_fout\n",
    "                                kernel_size=(3,3),              # kernel size along x and y\n",
    "                                strides=(1,1),                  # stride performed along x and y\n",
    "                                padding='SAME',                 # padding of input to adjust output size\n",
    "                                use_bias=True,                  # learn bias values for conv layer\n",
    "                                activation=activation)(input)   # apply activation function after conv operation\n",
    "# convolutional layer 2\n",
    "conv_out2 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out1)\n",
    "# convolutional layer 3\n",
    "residual    = tf.keras.layers.Conv2D(filters=1,\n",
    "                                kernel_size=(3,3),\n",
    "                                strides=(1,1),\n",
    "                                padding='SAME',\n",
    "                                use_bias=True,\n",
    "                                activation=activation)(conv_out2)\n",
    "# residual connection\n",
    "output = tf.keras.layers.Add()([input, residual])\n",
    "\n",
    "# instantiate a keras functional model: combine layers into a model with specified inputs and outputs\n",
    "model = tf.keras.Model(input, output, name='Residual3layerCNN')\n",
    "\n",
    "# print model overview\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLtH7LN3jBaw"
   },
   "source": [
    "### Build model\n",
    "Compile the model, assign an optimizer, loss function and validation metrics. Prepare some keras callbacks to monitor training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uO-aSnHDawFJ"
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),      # used optimizer with chosen learning rate\n",
    "              loss='mse',                                                   # loss function \n",
    "              metrics=['mse', 'mae'])                                       # evaluation metrics (for training and validation set)\n",
    "\n",
    "# define callbacks to monitor model\n",
    "keras_callbacks = tutorial.get_callbacks(validation_generator, model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBZObgNmBrzu"
   },
   "source": [
    "## Tensorboard\n",
    "Start the Tensorboard [optional] to monitor training progress and display validation outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRkAJB8nawFQ"
   },
   "outputs": [],
   "source": [
    "# start Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jskfeAhyB3KN"
   },
   "source": [
    "## Training\n",
    "Train the configured and compiled model. Monitor training progress with validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EBCEzPcQawFT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.1515 - mse: 0.1515 - mae: 0.2703 - val_loss: 0.1324 - val_mse: 0.1324 - val_mae: 0.2294\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1320 - mse: 0.1320 - mae: 0.2277 - val_loss: 0.1314 - val_mse: 0.1314 - val_mae: 0.2245\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1313 - mse: 0.1313 - mae: 0.2247 - val_loss: 0.1315 - val_mse: 0.1315 - val_mae: 0.2238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43144d4208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with training set and evaluate its performance with the validation set\n",
    "model.fit(training_generator,                     # training set\n",
    "          validation_data=validation_generator,   # validation set\n",
    "          epochs=3,                               # number of epochs to train the model\n",
    "          callbacks=keras_callbacks)              # callbacks to monitor or control training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qlWxTOzCApS"
   },
   "source": [
    "## Testing\n",
    "Test the trained model to predict a denoised output and to display performance (metrics) on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aPWDzA18awFZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.1313 - mse: 0.1313 - mae: 0.2236\n"
     ]
    }
   ],
   "source": [
    "# evaluate trained model\n",
    "loss_metric_test = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict with trained model\n",
    "inputs, outputs = test_generator.__getitem__(0)\n",
    "predicted_output = model.predict(inputs)\n",
    "\n",
    "# display the predicted output\n",
    "import matplotlib.pyplot as plt\n",
    "icase = 0  # display the first example\n",
    "plt.figure()\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(np.squeeze(np.abs(inputs[icase,])), cmap='gray')\n",
    "plt.title('Noisy')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(np.squeeze(np.abs(predicted_output[icase,])), cmap='gray')\n",
    "plt.title('Recon')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(np.squeeze(np.abs(outputs[icase,])), cmap='gray')\n",
    "plt.title('Target')\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tutorial_denoising_real.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "26c4402bb8476a31d8c429f22841c868a499a7e31d9c723639b1a5309d819501"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('optox_midas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
